# -*- coding: utf-8 -*-
"""recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vr3VnE7NI2mqZboide2HShQq0na37OEI
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from google.colab import drive
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

drive.mount('/content/gdrive')

movies = pd.read_csv('/content/gdrive/MyDrive/Kaggle/movies2.csv')
tags = pd.read_csv('/content/gdrive/MyDrive/Kaggle/tags.csv')
ratings = pd.read_csv('/content/gdrive/MyDrive/Kaggle/ratings.csv')
links = pd.read_csv('/content/gdrive/MyDrive/Kaggle/links.csv')

movies.head()

tags.head()

ratings

links

"""Menggabungkan seluruh movieId pada kategori movie,kemudian mengurutkan data dan mengambil data yang unik(tidak sama dengan yg lain)"""

all_movies = np.concatenate((
    movies.movieId.unique(),
    tags.movieId.unique(),
    ratings.movieId.unique(),
    links.movieId.unique(),
))

all_movies = np.sort(np.unique(all_movies))

print('number of all movies: ', len(all_movies))

"""Menggabungkan semua userId pada users, dalam hal ini userId pada file tags dan ratings, kemudian mengambil nilai unik pada users yang diurutkan"""

users = np.concatenate((
    tags.userId.unique(),
    ratings.userId.unique(),
))

users = np.sort(np.unique(users))
print('number of all users: ', len(users))

"""Dapat dilihat pada jumlah seluruh pengguna ada sekitar 610

Menggabungkan movies,tags,ratings, dan links pada movinfo. Kemudian di merge ratings dan movinfo dengan left join (dalam hal ini mengambil data ratings(df kiri(left)) dan membuang baris dari df kanan yang tidak memiliki kecocokan dikolom kunci df kiri(left)).
"""

movinfo= pd.concat([ movies, tags, ratings, links])
movie = pd.merge(ratings, movinfo, on='movieId', how='left')
movie.head()

"""Untuk melihat banyaknya baris dan kolom bisa menggunakan shape"""

movie.shape

"""Setelah digabungkan digroupby berdasarkan movieId"""

movie.groupby('movieId').sum()

"""Melakukan merge ratings dan movies dengan left join (dalam hal ini mengambil data ratings(df kiri(left)) dan membuang baris dari df kanan yang tidak memiliki kecocokan dikolom kunci df kiri(left)) dalam hal ini berdasarkan movieId dan disimpan di df movies_names."""

movies_names = pd.merge(ratings, movies[['movieId','title','genres']], on='movieId', how='left')
movies_names

"""Melakukan penggabungan data movies_name dan tags dengan left join berdasarkan movieId"""

movies_merge = pd.merge(movies_names, tags[['movieId','tag']], on='movieId', how='left')
movies_merge

"""Pada output diatas masih terdapat nilai NaN, maka dicek menggunakan isnull apakah masih ada missing values"""

movies_merge.isnull().sum()

"""Dapat dilihat pada output diatas bahwa terdapat missing values sekitar 52549 pada kolom tags,maka bisa menggunakan dropna() untuk menghapus missing values yang direpresentasikan dengan Nan."""

movies_merge = movies_merge.dropna()
movies_merge

"""Setelah menghapus dengan dropna() cek kembali apakah masih ada missing values"""

movies_merge.isnull().sum()

"""Pada output diatas bisa dilihat bahwa sudah tidak ada missing values

Menyimpan data yang tidak ada missing values pada movies_merge yang di urutkan(sort) berdasarkan movieId
"""

movies_merge = movies_merge.sort_values('movieId', ascending=True)
movies_merge

"""Setelah diurutkan terdapat sekitar 233213 baris

Membuang data duplikat dengan drop_duplicates pada movieId,sehingga movieId tidak ada yang sama
"""

movies_merge = movies_merge.drop_duplicates('movieId')
movies_merge

"""Mengkonversi movieId,title, dan genres dalam dalam bentuk list dan disimpan di id, names, dan genres"""

id = movies_merge['movieId'].tolist()
names = movies_merge['title'].tolist()
genres = movies_merge['genres'].tolist()

"""Membuat df baru dengan nama new_movies yang menyimpan id, names, dan genres"""

new_movies = pd.DataFrame({
    'id': id,
    'names': names,
    'genres': genres
})
new_movies.head()

new_movies.shape

"""Terdapat sekitar 1554 film pada df new_movies

Melakukan perhitungan idf pada data genre
Mapping array dari fitur index integer ke fitur nama
"""

tf = TfidfVectorizer()
tf.fit(new_movies['genres'])
tf.get_feature_names_out()

tfidf_matrix = tf.fit_transform(new_movies['genres'])
tfidf_matrix.shape

"""Matriks yang dimiliki berukuran (1554,24) Dimana nilai 1554 merupakan ukuran data dan 24 adalah banyaknya kategori genres

Untuk menghasilkan dalam bentuk matriks, digunakan fungsi todense()
"""

tfidf_matrix.todense()

"""Selanjutnya jika ingin melihat matriks tfidf untuk beberapa nama film (disini saya menampilkan 10 nama film)berdasarkan genres"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=new_movies.names
).sample(22, axis=1).sample(10, axis=0)

"""Cosine Similarity"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Untuk melihat matriks kesamaan setiap film, dibawah ini akan menampilkan nama film dalam 5 sampel kolom(axis =1) dan 10 sampel baris(axis = 0)"""

cosine_sim_data = pd.DataFrame(cosine_sim, index=new_movies['names'], columns=new_movies['names'])
print('Shape:', cosine_sim_data.shape)
cosine_sim_data.sample(5, axis=1).sample(10, axis=0)

"""Membuat fungsi rekomendasi dengan parameter sbb:
movies_name, similarity_data, items, dan k
"""

def movrecomm(movies_name, similarity_data=cosine_sim_data, items=new_movies[['names', 'genres']], k=3):
    index = similarity_data.loc[:,movies_name].to_numpy().argpartition(
        range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(movies_name, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

new_movies[new_movies.names.eq('The Hobbit: The Battle of the Five Armies (2014)')]

movrecomm('The Hobbit: The Battle of the Five Armies (2014)')

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""Data Understanding Collaborative Filter"""

dataf = ratings
dataf

"""data ratings memiliki 100836 baris dan 4 kolom

Encode fitur user
"""

userid = dataf['userId'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(userid)}
user_encoded_to_user = {i: x for i, x in enumerate(userid)}

""" Mengubah movieId menjadi list tanpa nilai yang sama
 Melakukan proses encoding movieId
 Melakukan proses encoding angka ke movieId
 Selanjutnya, petakan userId dan movieId ke dataframe yang berkaitan.
"""

movieid = dataf['movieId'].unique().tolist()
movie_to_movie_encoded = {x: i for i, x in enumerate(movieid)}
movie_encoded_to_movie = {i: x for i, x in enumerate(movieid)}

dataf['users'] = dataf['userId'].map(user_to_user_encoded)
dataf['movies'] = dataf['movieId'].map(movie_to_movie_encoded)

"""Mengecek jumlah users dan movie, dan mengubah nilai ratings menjadi float"""

num_users = len(user_to_user_encoded)
num_movie = len(movie_encoded_to_movie)

dataf['ratings'] = dataf['rating'].values.astype(np.float32)

min_rating = min(dataf['rating'])
max_rating = max(dataf['rating'])

"""Mencetak ada berapa banyak user dan film serta nilai rating minimum dan maksimum"""

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(num_users, num_movie, min_rating, max_rating))

"""Mengacak data agar distribusinya random disimpan pada dataframe dataf"""

dataf = dataf.sample(frac=1, random_state=42)
dataf

"""Memetakan data genres dan movies menjadi satu value,membuat variabel y untuk membuat ratings, membagi data menjadi 70% data train dan 30% data validasi"""

x = dataf[['users', 'movies']].values
y = dataf['ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indexes = int(0.7 * dataf.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indexes],
    x[train_indexes:],
    y[:train_indexes],
    y[train_indexes:]
)

print(x, y)

"""Proses Training"""

class RecommenderNet(tf.keras.Model):

  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.movie_embedding = layers.Embedding(
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    movie_vector = self.movie_embedding(inputs[:, 1])
    movie_bias = self.movie_bias(inputs[:, 1])

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x)

"""Compile model, menggunakan metrik evaluasi RMSE(RootMeanSquaredError)"""

model = RecommenderNet(num_users, num_movie, 50)
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Training"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""Visualisasi Metrik dengan plot"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend(['train', 'val'], loc='upper right')
plt.show()

"""Rekomendasi berdasarkan collaborative filtering"""

movies_data = new_movies
data = pd.read_csv('/content/gdrive/MyDrive/Kaggle/ratings.csv')

userid = data.userId.sample(1).iloc[0]
movies_watched_by_user = data[data.userId == userid]

movies_not_watched = movies_data[~movies_data['id'].isin(movies_watched_by_user.movieId.values)]['id']
movies_not_watched = list(
    set(movies_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movies_not_watched = [[movie_to_movie_encoded.get(x)] for x in movies_not_watched]
user_encoder = user_to_user_encoded.get(userid)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)
)

ratings = model.predict(user_movie_array).flatten()
top_ratings_index = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movies_not_watched[x][0]) for x in top_ratings_index
]

top_movies_user = (
    movies_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

print('Showing recommendations for users: {}'.format(userid))
print('===' * 14)
print('movie with high ratings from user')
print('----' * 10)

movies_data_rows = movies_data[movies_data['id'].isin(top_movies_user)]
for row in movies_data_rows.itertuples():
    print(row.names, ':', row.genres)

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)
recommended_movie = movies_data[movies_data['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.names, ':', row.genres)